#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Ch∆∞∆°ng tr√¨nh d·ª± ƒëo√°n v√† ph√¢n t√≠ch ti√™u th·ª• nƒÉng l∆∞·ª£ng s·ª≠ d·ª•ng Spark MLlib
Author: Energy Analytics Team
Date: 2025
"""

from pyspark.sql import SparkSession
from pyspark.sql.functions import (col, concat_ws, to_timestamp, hour, dayofweek, 
                                  month, weekofyear, year, dayofmonth, lit, regexp_extract, when,
                                  avg, stddev, count, sum)
from pyspark.sql.functions import min as spark_min, max as spark_max
from pyspark.sql.types import *
from pyspark.ml.feature import VectorAssembler, StandardScaler
from pyspark.ml.regression import LinearRegression, RandomForestRegressor, GBTRegressor
from pyspark.ml.evaluation import RegressionEvaluator
from pyspark.ml import Pipeline
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
import random

def create_spark_session():
    """T·∫°o Spark Session"""
    print("Kh·ªüi t·∫°o Spark Session...")
    spark = SparkSession.builder \
        .appName("EnergyConsumptionPredictionAnalysis") \
        .config("spark.sql.adaptive.enabled", "true") \
        .config("spark.sql.adaptive.coalescePartitions.enabled", "true") \
        .config("spark.sql.legacy.timeParserPolicy", "LEGACY") \
        .config("spark.sql.execution.arrow.pyspark.enabled", "false") \
        .getOrCreate()
    
    spark.sparkContext.setLogLevel("WARN")
    print("Spark Session ƒë√£ ƒë∆∞·ª£c t·∫°o th√†nh c√¥ng!")
    return spark

def load_and_preprocess_data(spark, file_path):
    """T·∫£i v√† ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu"""
    print("\nƒêang t·∫£i v√† ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu...")
    
    df = spark.read.csv(file_path, header=True, sep=";", inferSchema=False)
    print(f"D·ªØ li·ªáu g·ªëc c√≥ {df.count()} d√≤ng v√† {len(df.columns)} c·ªôt")
    
    print("\nKi·ªÉm tra d·ªØ li·ªáu thi·∫øu...")
    for c in df.columns:
        n_missing = df.filter((col(c).isNull()) | (col(c) == "") | (col(c) == "?")).count()
        if n_missing > 0:
            print(f"C·ªôt {c}: {n_missing} gi√° tr·ªã thi·∫øu")
    
    cols_to_clean = [
        "Global_active_power", "Global_reactive_power", "Voltage",
        "Global_intensity", "Sub_metering_1", "Sub_metering_2", "Sub_metering_3"
    ]
    
    print("\nL√†m s·∫°ch d·ªØ li·ªáu...")
    for c in cols_to_clean:
        df = df.filter((col(c).isNotNull()) & (col(c) != "?"))
    
    for c in cols_to_clean:
        df = df.withColumn(c, col(c).cast("float"))
    
    print("T·∫°o c·ªôt th·ªùi gian...")
    try:
        df = df.withColumn("datetime", to_timestamp(
            concat_ws(' ', df.Date, df.Time), "dd/MM/yyyy HH:mm:ss"))
        
        null_count = df.filter(col("datetime").isNull()).count()
        if null_count > 0:
            print(f"C√≥ {null_count} d√≤ng kh√¥ng parse ƒë∆∞·ª£c datetime, ƒëang th·ª≠ format kh√°c...")
            df = df.withColumn("datetime", to_timestamp(
                concat_ws(' ', df.Date, df.Time), "d/M/yyyy H:mm:ss"))
            
            null_count_2 = df.filter(col("datetime").isNull()).count()
            if null_count_2 > 0:
                print(f"V·∫´n c√≥ {null_count_2} d√≤ng l·ªói, s·∫Ω lo·∫°i b·ªè...")
                df = df.filter(col("datetime").isNotNull())
        
    except Exception as e:
        print(f"L·ªói parse datetime: {e}")
        print("ƒêang s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p thay th·∫ø...")
        
        df = df.withColumn("day", regexp_extract(col("Date"), r"(\d+)/\d+/\d+", 1).cast("int")) \
               .withColumn("month", regexp_extract(col("Date"), r"\d+/(\d+)/\d+", 1).cast("int")) \
               .withColumn("year", regexp_extract(col("Date"), r"\d+/\d+/(\d+)", 1).cast("int")) \
               .withColumn("hour_time", regexp_extract(col("Time"), r"(\d+):\d+:\d+", 1).cast("int")) \
               .withColumn("minute", regexp_extract(col("Time"), r"\d+:(\d+):\d+", 1).cast("int")) \
               .withColumn("second", regexp_extract(col("Time"), r"\d+:\d+:(\d+)", 1).cast("int"))
        
        df = df.withColumn("datetime_str", 
                          concat_ws("-", 
                                   col("year"), 
                                   when(col("month") < 10, concat_ws("", lit("0"), col("month"))).otherwise(col("month")),
                                   when(col("day") < 10, concat_ws("", lit("0"), col("day"))).otherwise(col("day"))) + " " +
                          concat_ws(":", 
                                   when(col("hour_time") < 10, concat_ws("", lit("0"), col("hour_time"))).otherwise(col("hour_time")),
                                   when(col("minute") < 10, concat_ws("", lit("0"), col("minute"))).otherwise(col("minute")),
                                   when(col("second") < 10, concat_ws("", lit("0"), col("second"))).otherwise(col("second"))))
        
        df = df.withColumn("datetime", to_timestamp(col("datetime_str"), "yyyy-MM-dd HH:mm:ss"))
        df = df.drop("day", "month", "year", "hour_time", "minute", "second", "datetime_str")
    
    df = df.withColumn("year", year(col("datetime"))) \
           .withColumn("month", month(col("datetime"))) \
           .withColumn("day", dayofmonth(col("datetime"))) \
           .withColumn("hour", hour(col("datetime"))) \
           .withColumn("dayofweek", dayofweek(col("datetime"))) \
           .withColumn("weekofyear", weekofyear(col("datetime")))
    
    print(f"D·ªØ li·ªáu sau x·ª≠ l√Ω: {df.count()} d√≤ng")
    return df

def handle_outliers(df, target_col="Global_active_power"):
    """X·ª≠ l√Ω outliers"""
    print(f"\nX·ª≠ l√Ω outliers cho c·ªôt {target_col}...")
    
    Q1, Q3 = df.approxQuantile(target_col, [0.25, 0.75], 0.01)
    IQR = Q3 - Q1
    lower = Q1 - 1.5 * IQR
    upper = Q3 + 1.5 * IQR
    
    outlier_count = df.filter((df[target_col] < lower) | (df[target_col] > upper)).count()
    print(f"S·ªë l∆∞·ª£ng outliers: {outlier_count}")
    
    df_clean = df.filter((df[target_col] >= lower) & (df[target_col] <= upper))
    print(f"D·ªØ li·ªáu sau khi lo·∫°i outliers: {df_clean.count()} d√≤ng")
    return df_clean

def analyze_and_visualize_data(df_no_outlier):
    """Ph√¢n t√≠ch v√† tr·ª±c quan h√≥a d·ªØ li·ªáu ti√™u th·ª• nƒÉng l∆∞·ª£ng"""
    print("\n" + "="*60)
    print("PH·∫¶N 3: PH√ÇN T√çCH V√Ä TR·ª∞C QUAN H√ìA D·ªÆ LI·ªÜU TI√äU TH·ª§ NƒÇNG L∆Ø·ª¢NG")
    print("="*60)
    
    plt.style.use('default')
    sns.set_palette("husl")
    
    df_analysis = df_no_outlier
    
    print("\nPh√¢n t√≠ch ti√™u th·ª• theo gi·ªù...")
    hourly_consumption = df_analysis.groupBy("hour") \
        .agg(avg("Global_active_power").alias("avg_power"),
             stddev("Global_active_power").alias("std_power"),
             spark_min("Global_active_power").alias("min_power"),
             spark_max("Global_active_power").alias("max_power"),
             count("Global_active_power").alias("count_records")) \
        .orderBy("hour")

    print("=== TI√äU TH·ª§ ƒêI·ªÜN THEO GI·ªú TRONG NG√ÄY ===")
    hourly_consumption.show(24)

    hourly_pd = hourly_consumption.toPandas()

    plt.figure(figsize=(15, 10))

    plt.subplot(2, 2, 1)
    plt.plot(hourly_pd['hour'], hourly_pd['avg_power'], marker='o', linewidth=2, markersize=6)
    plt.fill_between(hourly_pd['hour'], 
                     hourly_pd['avg_power'] - hourly_pd['std_power'],
                     hourly_pd['avg_power'] + hourly_pd['std_power'], 
                     alpha=0.3)
    plt.title('M·ª©c ti√™u th·ª• ƒëi·ªán trung b√¨nh theo gi·ªù trong ng√†y', fontsize=14, fontweight='bold')
    plt.xlabel('Gi·ªù trong ng√†y')
    plt.ylabel('C√¥ng su·∫•t (kW)')
    plt.grid(True, alpha=0.3)
    plt.xticks(range(0, 24))

    plt.subplot(2, 2, 2)
    x = hourly_pd['hour']
    plt.plot(x, hourly_pd['min_power'], marker='v', label='Minimum', linewidth=2, markersize=6, color='blue')
    plt.plot(x, hourly_pd['max_power'], marker='^', label='Maximum', linewidth=2, markersize=6, color='red')
    plt.fill_between(x, hourly_pd['min_power'], hourly_pd['max_power'], alpha=0.2, color='gray')
    plt.title('M·ª©c ti√™u th·ª• Min-Max theo gi·ªù', fontsize=14, fontweight='bold')
    plt.xlabel('Gi·ªù trong ng√†y')
    plt.ylabel('C√¥ng su·∫•t (kW)')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.xticks(range(0, 24))

    daily_consumption = df_analysis.groupBy("dayofweek") \
        .agg(avg("Global_active_power").alias("avg_power"),
             stddev("Global_active_power").alias("std_power"),
             count("Global_active_power").alias("count_records")) \
        .orderBy("dayofweek")

    daily_pd = daily_consumption.toPandas()
    days_name = ['Ch·ªß nh·∫≠t', 'Th·ª© 2', 'Th·ª© 3', 'Th·ª© 4', 'Th·ª© 5', 'Th·ª© 6', 'Th·ª© 7']
    daily_pd['day_name'] = days_name

    plt.subplot(2, 2, 3)
    bars = plt.bar(daily_pd['day_name'], daily_pd['avg_power'], 
                   color=['red' if day in ['Ch·ªß nh·∫≠t', 'Th·ª© 7'] else 'steelblue' for day in daily_pd['day_name']],
                   alpha=0.8)
    plt.title('M·ª©c ti√™u th·ª• ƒëi·ªán trung b√¨nh theo ng√†y trong tu·∫ßn', fontsize=14, fontweight='bold')
    plt.xlabel('Ng√†y trong tu·∫ßn')
    plt.ylabel('C√¥ng su·∫•t trung b√¨nh (kW)')
    plt.xticks(rotation=45)
    for bar, value in zip(bars, daily_pd['avg_power']):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                 f'{value:.3f}', ha='center', va='bottom', fontweight='bold')

    monthly_consumption = df_analysis.groupBy("month") \
        .agg(avg("Global_active_power").alias("avg_power"),
             sum("Global_active_power").alias("total_power"),
             stddev("Global_active_power").alias("std_power")) \
        .orderBy("month")

    monthly_pd = monthly_consumption.toPandas()
    months_name = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun',
                   'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']
    monthly_pd['month_name'] = [months_name[i-1] for i in monthly_pd['month']]

    plt.subplot(2, 2, 4)
    plt.plot(monthly_pd['month_name'], monthly_pd['avg_power'], 
             marker='s', linewidth=3, markersize=8, color='green')
    plt.title('Xu h∆∞·ªõng ti√™u th·ª• ƒëi·ªán theo th√°ng', fontsize=14, fontweight='bold')
    plt.xlabel('Th√°ng')
    plt.ylabel('C√¥ng su·∫•t trung b√¨nh (kW)')
    plt.xticks(rotation=45)
    plt.grid(True, alpha=0.3)

    plt.tight_layout()
    plt.savefig('energy_consumption_hourly_analysis.png', dpi=300, bbox_inches='tight')
    try:
        plt.show()
    except Exception as e:
        print(f"Kh√¥ng th·ªÉ hi·ªÉn th·ªã bi·ªÉu ƒë·ªì: {e}. Bi·ªÉu ƒë·ªì ƒë√£ ƒë∆∞·ª£c l∆∞u th√†nh file.")

    print("\n=== TH·ªêNG K√ä M√î T·∫¢ CHI TI·∫æT ===")
    stats_summary = df_analysis.select("Global_active_power") \
        .summary("count", "mean", "stddev", "min", "25%", "50%", "75%", "max")
    stats_summary.show()

    plt.figure(figsize=(15, 5))

    plt.subplot(1, 3, 1)
    power_data = df_analysis.select("Global_active_power").rdd.flatMap(lambda x: x).collect()
    sample_size = min(10000, len(power_data))
    power_sample = random.sample(power_data, sample_size)
    plt.hist(power_sample, bins=50, density=True, alpha=0.7, color='skyblue', edgecolor='black')
    plt.title('Ph√¢n ph·ªëi m·ª©c ti√™u th·ª• ƒëi·ªán', fontsize=14, fontweight='bold')
    plt.xlabel('C√¥ng su·∫•t (kW)')
    plt.ylabel('M·∫≠t ƒë·ªô')
    plt.grid(True, alpha=0.3)

    plt.subplot(1, 3, 2)
    plt.boxplot(power_sample, patch_artist=True, 
                boxprops=dict(facecolor='lightgreen', alpha=0.7),
                medianprops=dict(color='red', linewidth=2))
    plt.title('Box Plot - Ph√¢n ph·ªëi ti√™u th·ª• ƒëi·ªán', fontsize=14, fontweight='bold')
    plt.ylabel('C√¥ng su·∫•t (kW)')
    plt.grid(True, alpha=0.3)

    plt.subplot(1, 3, 3)
    peak_hours_data = df_analysis.filter(col("hour").isin([7, 8, 19, 20, 21])) \
                               .select("hour", "Global_active_power") \
                               .sample(0.1)
    peak_hours_pd = peak_hours_data.toPandas()
    if not peak_hours_pd.empty:
        sns.violinplot(data=peak_hours_pd, x='hour', y='Global_active_power')
        plt.title('Ph√¢n ph·ªëi ti√™u th·ª• trong gi·ªù cao ƒëi·ªÉm', fontsize=14, fontweight='bold')
        plt.xlabel('Gi·ªù')
        plt.ylabel('C√¥ng su·∫•t (kW)')

    plt.tight_layout()
    plt.savefig('energy_distribution_analysis.png', dpi=300, bbox_inches='tight')
    try:
        plt.show()
    except Exception as e:
        print(f"Kh√¥ng th·ªÉ hi·ªÉn th·ªã bi·ªÉu ƒë·ªì: {e}. Bi·ªÉu ƒë·ªì ƒë√£ ƒë∆∞·ª£c l∆∞u th√†nh file.")

    print("\n=== PH√ÇN T√çCH C√ÅC THI·∫æT B·ªä TI√äU TH·ª§ PH·ª§ ===")
    submeter_contrib = df_analysis.agg(
        avg("Sub_metering_1").alias("avg_sub1"),
        avg("Sub_metering_2").alias("avg_sub2"), 
        avg("Sub_metering_3").alias("avg_sub3"),
        avg("Global_active_power").alias("avg_total")
    ).collect()[0]

    print(f"Sub-metering 1 (B·∫øp): {submeter_contrib['avg_sub1']:.3f} kW ({min(100, submeter_contrib['avg_sub1']/submeter_contrib['avg_total']*100):.1f}%)")
    print(f"Sub-metering 2 (Gi·∫∑t ·ªßi): {submeter_contrib['avg_sub2']:.3f} kW ({min(100, submeter_contrib['avg_sub2']/submeter_contrib['avg_total']*100):.1f}%)")
    print(f"Sub-metering 3 (ƒêi·ªÅu h√≤a/N∆∞·ªõc n√≥ng): {submeter_contrib['avg_sub3']:.3f} kW ({min(100, submeter_contrib['avg_sub3']/submeter_contrib['avg_total']*100):.1f}%)")

    plt.figure(figsize=(15, 5))

    plt.subplot(1, 3, 1)
    sub1 = submeter_contrib['avg_sub1']
    sub2 = submeter_contrib['avg_sub2'] 
    sub3 = submeter_contrib['avg_sub3']
    total = submeter_contrib['avg_total']
    
    sub_total = sub1 + sub2 + sub3
    if sub_total > total:
        factor = total / sub_total * 0.9
        sub1 = sub1 * factor
        sub2 = sub2 * factor  
        sub3 = sub3 * factor
        other = total - sub1 - sub2 - sub3
    else:
        other = total - sub_total
    
    other = max(0, other)
    
    labels = ['B·∫øp', 'Gi·∫∑t ·ªßi', 'ƒêi·ªÅu h√≤a/N∆∞·ªõc n√≥ng', 'Kh√°c']
    sizes = [sub1, sub2, sub3, other]
    colors = ['gold', 'lightcoral', 'lightskyblue', 'lightgray']
    explode = (0.05, 0.05, 0.05, 0)

    valid_indices = [i for i, size in enumerate(sizes) if size > 0]
    valid_labels = [labels[i] for i in valid_indices]
    valid_sizes = [sizes[i] for i in valid_indices]
    valid_colors = [colors[i] for i in valid_indices]
    valid_explode = [explode[i] for i in valid_indices]

    plt.pie(valid_sizes, explode=valid_explode, labels=valid_labels, colors=valid_colors, 
            autopct='%1.1f%%', shadow=True, startangle=90)
    plt.title('T·ª∑ l·ªá ƒë√≥ng g√≥p ti√™u th·ª• ƒëi·ªán theo thi·∫øt b·ªã', fontsize=14, fontweight='bold')

    submeter_hourly = df_analysis.groupBy("hour") \
        .agg(avg("Sub_metering_1").alias("avg_sub1"),
             avg("Sub_metering_2").alias("avg_sub2"),
             avg("Sub_metering_3").alias("avg_sub3")) \
        .orderBy("hour")

    submeter_hourly_pd = submeter_hourly.toPandas()

    plt.subplot(1, 3, 2)
    plt.plot(submeter_hourly_pd['hour'], submeter_hourly_pd['avg_sub1'], 
             marker='o', label='B·∫øp', linewidth=2)
    plt.plot(submeter_hourly_pd['hour'], submeter_hourly_pd['avg_sub2'], 
             marker='s', label='Gi·∫∑t ·ªßi', linewidth=2)
    plt.plot(submeter_hourly_pd['hour'], submeter_hourly_pd['avg_sub3'], 
             marker='^', label='ƒêi·ªÅu h√≤a/N∆∞·ªõc n√≥ng', linewidth=2)
    plt.title('Xu h∆∞·ªõng ti√™u th·ª• theo gi·ªù - T·ª´ng thi·∫øt b·ªã', fontsize=14, fontweight='bold')
    plt.xlabel('Gi·ªù trong ng√†y')
    plt.ylabel('C√¥ng su·∫•t (kW)')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.xticks(range(0, 24))

    plt.subplot(1, 3, 3)
    heatmap_data = df_analysis.groupBy("hour", "dayofweek") \
        .agg(avg("Global_active_power").alias("avg_power")) \
        .toPandas()

    if not heatmap_data.empty:
        heatmap_pivot = heatmap_data.pivot(index='hour', columns='dayofweek', values='avg_power')
        heatmap_pivot.columns = ['CN', 'T2', 'T3', 'T4', 'T5', 'T6', 'T7']
        sns.heatmap(heatmap_pivot, annot=True, fmt='.3f', cmap='YlOrRd', 
                    cbar_kws={'label': 'C√¥ng su·∫•t (kW)'})
        plt.title('Heatmap ti√™u th·ª• ƒëi·ªán theo gi·ªù v√† ng√†y', fontsize=14, fontweight='bold')
        plt.xlabel('Ng√†y trong tu·∫ßn')
        plt.ylabel('Gi·ªù trong ng√†y')

    plt.tight_layout()
    plt.savefig('energy_device_analysis.png', dpi=300, bbox_inches='tight')
    try:
        plt.show()
    except Exception as e:
        print(f"Kh√¥ng th·ªÉ hi·ªÉn th·ªã bi·ªÉu ƒë·ªì: {e}. Bi·ªÉu ƒë·ªì ƒë√£ ƒë∆∞·ª£c l∆∞u th√†nh file.")

    return {
        'hourly_pd': hourly_pd,
        'daily_pd': daily_pd,
        'monthly_pd': monthly_pd,
        'submeter_contrib': submeter_contrib,
        'hourly_consumption': hourly_consumption,
        'daily_consumption': daily_consumption,
        'monthly_consumption': monthly_consumption
    }

def create_features(df):
    """T·∫°o feature vector"""
    print("\nT·∫°o feature vector...")
    
    feature_cols = [
        "Global_reactive_power", "Voltage", "Global_intensity",
        "Sub_metering_1", "Sub_metering_2", "Sub_metering_3",
        "hour", "dayofweek", "month"
    ]
    
    assembler = VectorAssembler(
        inputCols=feature_cols,
        outputCol="features_raw"
    )
    
    scaler = StandardScaler(
        inputCol="features_raw",
        outputCol="features",
        withStd=True,
        withMean=True
    )
    
    feature_pipeline = Pipeline(stages=[assembler, scaler])
    feature_model = feature_pipeline.fit(df)
    df_features = feature_model.transform(df)
    
    print("Feature vector ƒë√£ ƒë∆∞·ª£c t·∫°o v√† chu·∫©n h√≥a!")
    return df_features.select("features", "Global_active_power", "datetime", "hour", "dayofweek", "month"), feature_model

def train_models(train_data):
    """Hu·∫•n luy·ªán nhi·ªÅu m√¥ h√¨nh ML"""
    print("\nHu·∫•n luy·ªán c√°c m√¥ h√¨nh Machine Learning...")
    
    models = {}
    
    print("Hu·∫•n luy·ªán Linear Regression...")
    lr = LinearRegression(
        featuresCol="features",
        labelCol="Global_active_power",
        regParam=0.01
    )
    models['Linear Regression'] = lr.fit(train_data)
    
    print("Hu·∫•n luy·ªán Random Forest...")
    rf = RandomForestRegressor(
        featuresCol="features",
        labelCol="Global_active_power",
        numTrees=50,
        maxDepth=10,
        seed=42
    )
    models['Random Forest'] = rf.fit(train_data)
    
    print("Hu·∫•n luy·ªán Gradient Boosted Trees...")
    gbt = GBTRegressor(
        featuresCol="features",
        labelCol="Global_active_power",
        maxIter=50,
        maxDepth=8,
        seed=42
    )
    models['GBT'] = gbt.fit(train_data)
    
    print("T·∫•t c·∫£ m√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán!")
    return models

def evaluate_models(models, test_data):
    """ƒê√°nh gi√° c√°c m√¥ h√¨nh"""
    print("\nƒê√°nh gi√° hi·ªáu su·∫•t c√°c m√¥ h√¨nh...")
    
    evaluator_rmse = RegressionEvaluator(
        labelCol="Global_active_power",
        predictionCol="prediction",
        metricName="rmse"
    )
    
    evaluator_r2 = RegressionEvaluator(
        labelCol="Global_active_power",
        predictionCol="prediction",
        metricName="r2"
    )
    
    results = {}
    
    for name, model in models.items():
        predictions = model.transform(test_data)
        rmse = evaluator_rmse.evaluate(predictions)
        r2 = evaluator_r2.evaluate(predictions)
        
        results[name] = {
            'RMSE': rmse,
            'R¬≤': r2,
            'predictions': predictions
        }
        
        print(f"   {name}:")
        print(f"   RMSE: {rmse:.4f}")
        print(f"   R¬≤: {r2:.4f}")
    
    best_model_name = min(results.keys(), key=lambda x: results[x]['RMSE'])
    print(f"\nM√¥ h√¨nh t·ªët nh·∫•t: {best_model_name}")
    return results, best_model_name

def visualize_predictions(results, best_model_name):
    """Tr·ª±c quan h√≥a k·∫øt qu·∫£ d·ª± ƒëo√°n"""
    print("\nTr·ª±c quan h√≥a k·∫øt qu·∫£ d·ª± ƒëo√°n...")
    
    best_predictions = results[best_model_name]['predictions']
    pred_sample = best_predictions.select("Global_active_power", "prediction").sample(0.01).toPandas()
    
    if not pred_sample.empty:
        plt.figure(figsize=(12, 8))
        
        plt.subplot(2, 2, 1)
        plt.scatter(pred_sample['Global_active_power'], pred_sample['prediction'], alpha=0.5)
        plt.plot([pred_sample['Global_active_power'].min(), pred_sample['Global_active_power'].max()], 
                 [pred_sample['Global_active_power'].min(), pred_sample['Global_active_power'].max()], 
                 'r--', lw=2)
        plt.xlabel('Th·ª±c t·∫ø (kW)')
        plt.ylabel('D·ª± ƒëo√°n (kW)')
        plt.title(f'So s√°nh Th·ª±c t·∫ø vs D·ª± ƒëo√°n - {best_model_name}')
        plt.grid(True, alpha=0.3)
        
        plt.subplot(2, 2, 2)
        errors = pred_sample['prediction'] - pred_sample['Global_active_power']
        plt.hist(errors, bins=30, alpha=0.7, color='orange')
        plt.xlabel('Sai s·ªë (kW)')
        plt.ylabel('T·∫ßn su·∫•t')
        plt.title('Ph√¢n ph·ªëi sai s·ªë d·ª± ƒëo√°n')
        plt.grid(True, alpha=0.3)
        
        plt.subplot(2, 2, 3)
        model_names = list(results.keys())
        rmse_values = [results[name]['RMSE'] for name in model_names]
        model_colors = {'Linear Regression': 'blue', 'Random Forest': 'green', 'GBT': 'orange'}
        colors_rmse = [model_colors.get(name, 'gray') for name in model_names]
        bars = plt.bar(model_names, rmse_values, alpha=0.8, color=colors_rmse)
        plt.xlabel('M√¥ h√¨nh')
        plt.ylabel('RMSE')
        plt.title('So s√°nh RMSE c√°c m√¥ h√¨nh')
        plt.xticks(rotation=45)
        max_rmse = max(rmse_values)
        for bar, value in zip(bars, rmse_values):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max_rmse*0.02,
                     f'{value:.4f}', ha='center', va='bottom', fontweight='bold')
        plt.ylim(0, max_rmse * 1.15)
        
        plt.subplot(2, 2, 4)
        r2_values = [results[name]['R¬≤'] for name in model_names]
        colors_r2 = [model_colors.get(name, 'gray') for name in model_names]
        bars = plt.bar(model_names, r2_values, color=colors_r2, alpha=0.8)
        plt.xlabel('M√¥ h√¨nh')
        plt.ylabel('R¬≤ Score')
        plt.title('So s√°nh R¬≤ Score c√°c m√¥ h√¨nh')
        plt.xticks(rotation=45)
        plt.ylim(0, 1.4)
        for bar, value in zip(bars, r2_values):
            plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                     f'{value:.4f}', ha='center', va='bottom', fontweight='bold')
        
        plt.tight_layout()
        plt.savefig('model_performance_comparison.png', dpi=300, bbox_inches='tight')
        try:
            plt.show()
        except Exception as e:
            print(f"Kh√¥ng th·ªÉ hi·ªÉn th·ªã bi·ªÉu ƒë·ªì: {e}. Bi·ªÉu ƒë·ªì ƒë√£ ƒë∆∞·ª£c l∆∞u th√†nh file.")

def predict_yearly_consumption(df_features, best_model, spark, df_clean):
    """D·ª± ƒëo√°n m·ª©c ti√™u th·ª• nƒÉng l∆∞·ª£ng trung b√¨nh cho nƒÉm ti·∫øp theo"""
    print("\n" + "="*60)
    print("D·ª∞ ƒêO√ÅN TI√äU TH·ª§ NƒÇNG L∆Ø·ª¢NG CHO NƒÇM TI·∫æP THEO")
    print("="*60)
    
    current_year = df_features.select(year(col("datetime")).alias("year")).agg(spark_max("year")).collect()[0][0]
    next_year = current_year + 1
    print(f"üìÖ D·ª± ƒëo√°n cho nƒÉm: {next_year}")
    
    avg_stats = df_clean.agg(
        avg("Global_reactive_power").alias("avg_reactive"),
        avg("Voltage").alias("avg_voltage"),
        avg("Global_intensity").alias("avg_intensity"),
        avg("Sub_metering_1").alias("avg_sub1"),
        avg("Sub_metering_2").alias("avg_sub2"),
        avg("Sub_metering_3").alias("avg_sub3")
    ).collect()[0]
    
    prediction_data = []
    for month in range(1, 13):
        days_in_month = 31 if month in [1, 3, 5, 7, 8, 10, 12] else 30 if month in [4, 6, 9, 11] else 28
        for day in range(1, days_in_month + 1):
            dayofweek = ((day + month) % 7) + 1
            for hour in range(24):
                seasonal_factor = 1.15 if month in [12, 1, 2] else 1.1 if month in [6, 7, 8] else 0.95
                hourly_factor = 1.2 if 7 <= hour <= 9 or 18 <= hour <= 22 else 0.7 if 0 <= hour <= 5 else 1.0
                weekly_factor = 1.05 if dayofweek in [1, 7] else 1.0
                
                prediction_data.append({
                    'Global_reactive_power': float(avg_stats['avg_reactive'] * seasonal_factor * hourly_factor),
                    'Voltage': float(avg_stats['avg_voltage']),
                    'Global_intensity': float(avg_stats['avg_intensity'] * seasonal_factor * hourly_factor),
                    'Sub_metering_1': float(avg_stats['avg_sub1'] * seasonal_factor * hourly_factor),
                    'Sub_metering_2': float(avg_stats['avg_sub2'] * weekly_factor),
                    'Sub_metering_3': float(avg_stats['avg_sub3'] * seasonal_factor),
                    'hour': hour,
                    'dayofweek': dayofweek,
                    'month': month,
                    'year': next_year,
                    'day': day
                })
    
    schema = StructType([
        StructField("Global_reactive_power", FloatType(), True),
        StructField("Voltage", FloatType(), True),
        StructField("Global_intensity", FloatType(), True),
        StructField("Sub_metering_1", FloatType(), True),
        StructField("Sub_metering_2", FloatType(), True),
        StructField("Sub_metering_3", FloatType(), True),
        StructField("hour", IntegerType(), True),
        StructField("dayofweek", IntegerType(), True),
        StructField("month", IntegerType(), True),
        StructField("year", IntegerType(), True),
        StructField("day", IntegerType(), True)
    ])
    
    future_df = spark.createDataFrame(prediction_data, schema)
    feature_cols = [
        "Global_reactive_power", "Voltage", "Global_intensity",
        "Sub_metering_1", "Sub_metering_2", "Sub_metering_3",
        "hour", "dayofweek", "month"
    ]
    
    assembler = VectorAssembler(inputCols=feature_cols, outputCol="features_raw")
    scaler = StandardScaler(inputCol="features_raw", outputCol="features", withStd=True, withMean=True)
    feature_pipeline = Pipeline(stages=[assembler, scaler])
    sample_data = df_clean.sample(0.1)
    feature_model = feature_pipeline.fit(sample_data)
    future_df_features = feature_model.transform(future_df)
    
    print("üîÆ ƒêang th·ª±c hi·ªán d·ª± ƒëo√°n...")
    yearly_predictions = best_model.transform(future_df_features)
    
    yearly_stats = yearly_predictions.agg(
        avg("prediction").alias("avg_yearly_consumption"),
        spark_min("prediction").alias("min_consumption"),
        spark_max("prediction").alias("max_consumption"),
        stddev("prediction").alias("std_consumption")
    ).collect()[0]
    
    monthly_predictions = yearly_predictions.groupBy("month") \
        .agg(avg("prediction").alias("avg_monthly_consumption"),
             sum("prediction").alias("total_monthly_consumption")) \
        .orderBy("month")
    monthly_pred_pd = monthly_predictions.toPandas()
    
    hourly_predictions = yearly_predictions.groupBy("hour") \
        .agg(avg("prediction").alias("avg_pred"),
             stddev("prediction").alias("std_pred")) \
        .orderBy("hour")
    hourly_pred_pd = hourly_predictions.toPandas()
    
    print(f"\nüìä K·∫æT QU·∫¢ D·ª∞ ƒêO√ÅN NƒÇM {next_year}:")
    print(f"   üîπ M·ª©c ti√™u th·ª• trung b√¨nh: {yearly_stats['avg_yearly_consumption']:.3f} kW")
    print(f"   üîπ T·ªïng ti√™u th·ª• ∆∞·ªõc t√≠nh: {yearly_stats['avg_yearly_consumption'] * 8760:.0f} kWh/nƒÉm")
    print(f"   üîπ M·ª©c ti√™u th·ª• th·∫•p nh·∫•t: {yearly_stats['min_consumption']:.3f} kW")
    print(f"   üîπ M·ª©c ti√™u th·ª• cao nh·∫•t: {yearly_stats['max_consumption']:.3f} kW")
    print(f"   üîπ ƒê·ªô l·ªách chu·∫©n: {yearly_stats['std_consumption']:.3f} kW")
    
    plt.figure(figsize=(16, 12))
    
    plt.subplot(2, 3, 1)
    months_name = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']
    monthly_pred_pd['month_name'] = [months_name[i-1] for i in monthly_pred_pd['month']]
    bars = plt.bar(monthly_pred_pd['month_name'], monthly_pred_pd['avg_monthly_consumption'], 
                   color='lightblue', alpha=0.8, edgecolor='navy', linewidth=1)
    plt.title(f'D·ª± ƒëo√°n ti√™u th·ª• trung b√¨nh theo th√°ng ', fontsize=14, fontweight='bold')
    plt.xlabel('Th√°ng')
    plt.ylabel('C√¥ng su·∫•t trung b√¨nh (kW)')
    plt.xticks(rotation=45)
    plt.grid(True, alpha=0.3)
    for bar, value in zip(bars, monthly_pred_pd['avg_monthly_consumption']):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                 f'{value:.2f}', ha='center', va='bottom', fontsize=9, fontweight='bold')
    
    plt.subplot(2, 3, 2)
    plt.plot(monthly_pred_pd['month_name'], monthly_pred_pd['total_monthly_consumption']/1000, 
             marker='o', linewidth=3, markersize=8, color='red')
    plt.title(f'T·ªïng ti√™u th·ª• d·ª± ƒëo√°n theo th√°ng ', fontsize=14, fontweight='bold')
    plt.xlabel('Th√°ng')
    plt.ylabel('T·ªïng ti√™u th·ª• (MWh)')
    plt.xticks(rotation=45)
    plt.grid(True, alpha=0.3)
    
    plt.subplot(2, 3, 3)
    plt.plot(hourly_pred_pd['hour'], hourly_pred_pd['avg_pred'], 
             marker='s', linewidth=2, markersize=6, color='green', label='D·ª± ƒëo√°n trung b√¨nh')
    plt.fill_between(hourly_pred_pd['hour'],
                     hourly_pred_pd['avg_pred'] - 1.96 * hourly_pred_pd['std_pred'],
                     hourly_pred_pd['avg_pred'] + 1.96 * hourly_pred_pd['std_pred'],
                     alpha=0.3, color='green', label='Kho·∫£ng tin c·∫≠y 95%')
    plt.title(f'M·ª©c ti√™u th·ª• ƒëi·ªán trung b√¨nh theo gi·ªù trong ng√†y', fontsize=14, fontweight='bold')
    plt.xlabel('Gi·ªù trong ng√†y')
    plt.ylabel('C√¥ng su·∫•t trung b√¨nh (kW)')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.xticks(range(0, 24))
    
    plt.subplot(2, 3, 4)
    pred_sample = yearly_predictions.select("prediction").sample(0.1).rdd.flatMap(lambda x: x).collect()
    sample_size = min(5000, len(pred_sample))
    pred_sample = random.sample(pred_sample, sample_size)
    plt.hist(pred_sample, bins=50, density=True, alpha=0.7, color='orange', edgecolor='black')
    plt.axvline(yearly_stats['avg_yearly_consumption'], color='red', linestyle='--', 
                linewidth=2, label=f'Trung b√¨nh: {yearly_stats["avg_yearly_consumption"]:.3f} kW')
    plt.title('Ph√¢n ph·ªëi d·ª± ƒëo√°n ti√™u th·ª• nƒÉng l∆∞·ª£ng', fontsize=14, fontweight='bold')
    plt.xlabel('C√¥ng su·∫•t (kW)')
    plt.ylabel('M·∫≠t ƒë·ªô')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.subplot(2, 3, 5)
    seasons = {'Xu√¢n': [3, 4, 5], 'H√®': [6, 7, 8], 'Thu': [9, 10, 11], 'ƒê√¥ng': [12, 1, 2]}
    seasonal_consumption = []
    season_names = []
    for season, months in seasons.items():
        season_avg = monthly_pred_pd[monthly_pred_pd['month'].isin(months)]['avg_monthly_consumption'].mean()
        seasonal_consumption.append(season_avg)
        season_names.append(season)
    colors = ['lightgreen', 'gold', 'orange', 'lightblue']
    bars = plt.bar(season_names, seasonal_consumption, color=colors, alpha=0.8, edgecolor='black')
    plt.title(f'D·ª± ƒëo√°n ti√™u th·ª• theo m√πa', fontsize=14, fontweight='bold')
    plt.xlabel('M√πa')
    plt.ylabel('C√¥ng su·∫•t trung b√¨nh (kW)')
    for bar, value in zip(bars, seasonal_consumption):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                 f'{value:.3f}', ha='center', va='bottom', fontweight='bold')
    
    plt.subplot(2, 3, 6)
    current_year_avg = df_features.agg(avg("Global_active_power")).collect()[0][0]
    predicted_avg = yearly_stats['avg_yearly_consumption']
    growth_rate = ((predicted_avg - current_year_avg) / current_year_avg) * 100
    years = [current_year, next_year]
    consumptions = [current_year_avg, predicted_avg]
    plt.plot(years, consumptions, marker='o', linewidth=3, markersize=10, color='purple')
    plt.fill_between(years, consumptions, alpha=0.3, color='purple')
    plt.annotate(f'TƒÉng tr∆∞·ªüng: {growth_rate:+.1f}%', 
                xy=(next_year, predicted_avg), 
                xytext=(10, 10), textcoords='offset points',
                bbox=dict(boxstyle='round,pad=0.5', fc='yellow', alpha=0.7),
                arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))
    plt.title('Xu h∆∞·ªõng tƒÉng tr∆∞·ªüng ti√™u th·ª• nƒÉng l∆∞·ª£ng', fontsize=14, fontweight='bold')
    plt.xlabel('NƒÉm')
    plt.ylabel('C√¥ng su·∫•t trung b√¨nh (kW)')
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(f'yearly_energy_prediction_{next_year}.png', dpi=300, bbox_inches='tight')
    try:
        plt.show()
    except Exception as e:
        print(f"Kh√¥ng th·ªÉ hi·ªÉn th·ªã bi·ªÉu ƒë·ªì: {e}. Bi·ªÉu ƒë·ªì ƒë√£ ƒë∆∞·ª£c l∆∞u th√†nh file.")
    
    print(f"\nüìà PH√ÇN T√çCH CHI TI·∫æT D·ª∞ ƒêO√ÅN NƒÇM {next_year}:")
    print(f"   üîπ Xu h∆∞·ªõng tƒÉng tr∆∞·ªüng: {growth_rate:+.1f}%")
    if growth_rate > 5:
        print("   ‚ö†Ô∏è  C·∫£nh b√°o: M·ª©c tƒÉng tr∆∞·ªüng cao, c·∫ßn bi·ªán ph√°p ti·∫øt ki·ªám nƒÉng l∆∞·ª£ng")
    elif growth_rate < -5:
        print("   ‚úÖ T√≠ch c·ª±c: D·ª± ƒëo√°n gi·∫£m ti√™u th·ª•, hi·ªáu qu·∫£ ti·∫øt ki·ªám nƒÉng l∆∞·ª£ng")
    else:
        print("   üìä ·ªîn ƒë·ªãnh: M·ª©c tƒÉng tr∆∞·ªüng trong ph·∫°m vi b√¨nh th∆∞·ªùng")
    
    print(f"\nüèÜ TH√ÅNG TI√äU TH·ª§ CAO NH·∫§T D·ª∞ ƒêO√ÅN:")
    max_month_idx = monthly_pred_pd['avg_monthly_consumption'].idxmax()
    max_month = monthly_pred_pd.loc[max_month_idx]
    print(f"   üìÖ {max_month['month_name']}: {max_month['avg_monthly_consumption']:.3f} kW")
    
    print(f"\nüèÖ TH√ÅNG TI√äU TH·ª§ TH·∫§P NH·∫§T D·ª∞ ƒêO√ÅN:")
    min_month_idx = monthly_pred_pd['avg_monthly_consumption'].idxmin()
    min_month = monthly_pred_pd.loc[min_month_idx]
    print(f"   üìÖ {min_month['month_name']}: {min_month['avg_monthly_consumption']:.3f} kW")
    
    estimated_cost_per_kwh = 2500
    total_yearly_kwh = yearly_stats['avg_yearly_consumption'] * 8760
    estimated_yearly_cost = total_yearly_kwh * estimated_cost_per_kwh
    
    print(f"\nüí∞ ∆Ø·ªöC T√çNH CHI PH√ç NƒÇM {next_year}:")
    print(f"   üí° T·ªïng ti√™u th·ª•: {total_yearly_kwh:,.0f} kWh")
    print(f"   üíµ Chi ph√≠ ∆∞·ªõc t√≠nh: {estimated_yearly_cost:,.0f} VNƒê")
    print(f"   üí∏ Chi ph√≠ trung b√¨nh/th√°ng: {estimated_yearly_cost/12:,.0f} VNƒê")
    
    return yearly_predictions, yearly_stats, monthly_pred_pd, next_year

def generate_insights(analysis_results, yearly_stats, monthly_pred_pd, next_year):
    """T·∫°o insights t·ª´ ph√¢n t√≠ch v√† d·ª± ƒëo√°n h√†ng nƒÉm"""
    print("\n" + "="*80)
    print("B√ÅO C√ÅO T·ªîNG K·∫æT PH√ÇN T√çCH V√Ä D·ª∞ ƒêO√ÅN TI√äU TH·ª§ NƒÇNG L∆Ø·ª¢NG")
    print("="*80)
    
    hourly_pd = analysis_results['hourly_pd']
    daily_pd = analysis_results['daily_pd']
    monthly_pd = analysis_results['monthly_pd']
    submeter_contrib = analysis_results['submeter_contrib']
    
    peak_hour = hourly_pd.loc[hourly_pd['avg_power'].idxmax()]
    low_hour = hourly_pd.loc[hourly_pd['avg_power'].idxmin()]
    print(f"\nüïê GI·ªú CAO ƒêI·ªÇM: {int(peak_hour['hour'])}:00 - Ti√™u th·ª•: {peak_hour['avg_power']:.3f} kW")
    print(f"üïê GI·ªú TH·∫§P ƒêI·ªÇM: {int(low_hour['hour'])}:00 - Ti√™u th·ª•: {low_hour['avg_power']:.3f} kW")
    print(f"üìä CH√äNH L·ªÜCH: {peak_hour['avg_power'] - low_hour['avg_power']:.3f} kW ({(peak_hour['avg_power'] - low_hour['avg_power'])/low_hour['avg_power']*100:.1f}%)")

    peak_day = daily_pd.loc[daily_pd['avg_power'].idxmax()]
    low_day = daily_pd.loc[daily_pd['avg_power'].idxmin()]
    print(f"\nüìÖ NG√ÄY TI√äU TH·ª§ CAO NH·∫§T: {peak_day['day_name']} - {peak_day['avg_power']:.3f} kW")
    print(f"üìÖ NG√ÄY TI√äU TH·ª§ TH·∫§P NH·∫§T: {low_day['day_name']} - {low_day['avg_power']:.3f} kW")

    peak_month = monthly_pd.loc[monthly_pd['avg_power'].idxmax()]
    low_month = monthly_pd.loc[monthly_pd['avg_power'].idxmin()]
    print(f"\nüóìÔ∏è TH√ÅNG TI√äU TH·ª§ CAO NH·∫§T: {peak_month['month_name']} - {peak_month['avg_power']:.3f} kW")
    print(f"üóìÔ∏è TH√ÅNG TI√äU TH·ª§ TH·∫§P NH·∫§T: {low_month['month_name']} - {low_month['avg_power']:.3f} kW")

    print(f"\nüè† THI·∫æT B·ªä TI√äU TH·ª§ NHI·ªÄU NH·∫§T:")
    devices = [
        ("B·∫øp", submeter_contrib['avg_sub1']),
        ("ƒêi·ªÅu h√≤a/N∆∞·ªõc n√≥ng", submeter_contrib['avg_sub3']),
        ("Gi·∫∑t ·ªßi", submeter_contrib['avg_sub2'])
    ]
    devices.sort(key=lambda x: x[1], reverse=True)
    for i, (device, consumption) in enumerate(devices, 1):
        percentage = consumption/submeter_contrib['avg_total']*100
        print(f"   {i}. {device}: {consumption:.3f} kW ({percentage:.1f}%)")

    print(f"\nüîÆ D·ª∞ ƒêO√ÅN CHO NƒÇM {next_year}:")
    print(f"   M·ª©c ti√™u th·ª• trung b√¨nh d·ª± ƒëo√°n: {yearly_stats['avg_yearly_consumption']:.3f} kW")
    print(f"   Th√°ng cao ƒëi·ªÉm d·ª± ƒëo√°n: {monthly_pred_pd.loc[monthly_pred_pd['avg_monthly_consumption'].idxmax(), 'month_name']}")
    print(f"   Th√°ng th·∫•p ƒëi·ªÉm d·ª± ƒëo√°n: {monthly_pred_pd.loc[monthly_pred_pd['avg_monthly_consumption'].idxmin(), 'month_name']}")

    print(f"\nüí° ƒê·ªÄ XU·∫§T TI·∫æT KI·ªÜM NƒÇNG L∆Ø·ª¢NG:")
    print("1. üè† S·ª≠ d·ª•ng thi·∫øt b·ªã ƒëi·ªán v√†o gi·ªù th·∫•p ƒëi·ªÉm (gi·∫£m 15-20% chi ph√≠)")
    print("2. ‚ùÑÔ∏è ƒêi·ªÅu ch·ªânh nhi·ªát ƒë·ªô ƒëi·ªÅu h√≤a +2¬∞C v√†o gi·ªù cao ƒëi·ªÉm")
    print("3. üí° Thay th·∫ø ƒë√®n truy·ªÅn th·ªëng b·∫±ng ƒë√®n LED")
    print("4. üîå T·∫Øt c√°c thi·∫øt b·ªã standby v√†o ban ƒë√™m")
    print("5. ‚òÄÔ∏è C√¢n nh·∫Øc l·∫Øp ƒë·∫∑t h·ªá th·ªëng nƒÉng l∆∞·ª£ng m·∫∑t tr·ªùi")
    print("6. üè† S·ª≠ d·ª•ng thi·∫øt b·ªã c√≥ nh√£n nƒÉng l∆∞·ª£ng cao")
    print("7. üì± L·∫Øp ƒë·∫∑t h·ªá th·ªëng qu·∫£n l√Ω nƒÉng l∆∞·ª£ng th√¥ng minh")

    print(f"\nüìà TI·ªÄM NƒÇNG TI·∫æT KI·ªÜM:")
    potential_savings = peak_hour['avg_power'] * 0.15
    print(f"   Ti·∫øt ki·ªám ∆∞·ªõc t√≠nh: {potential_savings:.3f} kW/gi·ªù cao ƒëi·ªÉm")
    print(f"   T∆∞∆°ng ƒë∆∞∆°ng: {potential_savings * 24 * 30:.0f} kWh/th√°ng")

def save_analysis_results(analysis_results, spark):
    """L∆∞u k·∫øt qu·∫£ ph√¢n t√≠ch v√†o HDFS"""
    print(f"\nüíæ ƒêANG L∆ØU K·∫æT QU·∫¢ PH√ÇN T√çCH...")
    try:
        hourly_consumption = analysis_results['hourly_consumption']
        daily_consumption = analysis_results['daily_consumption']
        monthly_consumption = analysis_results['monthly_consumption']
        hourly_consumption.coalesce(1).write.mode("overwrite").csv("hdfs:///energy_analysis/hourly_consumption", header=True)
        daily_consumption.coalesce(1).write.mode("overwrite").csv("hdfs:///energy_analysis/daily_consumption", header=True)
        monthly_consumption.coalesce(1).write.mode("overwrite").csv("hdfs:///energy_analysis/monthly_consumption", header=True)
        print("‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ ph√¢n t√≠ch v√†o HDFS th√†nh c√¥ng!")
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói khi l∆∞u v√†o HDFS: {e}")
        print("üí° Tip: Ki·ªÉm tra c·∫•u h√¨nh Hadoop v√† quy·ªÅn ghi")

def main():
    """H√†m ch√≠nh"""
    print("üöÄ CH∆Ø∆†NG TR√åNH D·ª∞ ƒêO√ÅN V√Ä PH√ÇN T√çCH TI√äU TH·ª§ NƒÇNG L∆Ø·ª¢NG")
    print("="*60)
    
    import matplotlib
    matplotlib.use('Agg')
    
    spark = create_spark_session()
    
    try:
        file_path = "hdfs:///energy_data/household_power_consumption.txt"
        
        print("\n" + "="*50)
        print("PH·∫¶N 1: TI·ªÄN X·ª¨ L√ù D·ªÆ LI·ªÜU")
        print("="*50)
        df = load_and_preprocess_data(spark, file_path)
        
        print("\n" + "="*50)
        print("PH·∫¶N 2: X·ª¨ L√ù OUTLIERS")
        print("="*50)
        df_clean = handle_outliers(df)
        
        analysis_results = analyze_and_visualize_data(df_clean) # PH·∫¶N 3: PH√ÇN T√çCH V√Ä TR·ª∞C QUAN H√ìA D·ªÆ LI·ªÜU TI√äU TH·ª§ NƒÇNG L∆Ø·ª¢NG
        
        print("\n" + "="*50)
        print("PH·∫¶N 4: CHU·∫®N B·ªä D·ªÆ LI·ªÜU CHO MACHINE LEARNING")
        print("="*50)
        df_features, _ = create_features(df_clean)
        
        print("\nüìä Chia d·ªØ li·ªáu train/test (80/20)...")
        train_data, test_data = df_features.randomSplit([0.8, 0.2], seed=42)
        print(f"üìà Train: {train_data.count()} d√≤ng, Test: {test_data.count()} d√≤ng")
        
        print("\n" + "="*50)
        print("PH·∫¶N 5: HU·∫§N LUY·ªÜN C√ÅC M√î H√åNH MACHINE LEARNING")
        print("="*50)
        models = train_models(train_data)
        
        print("\n" + "="*50)
        print("PH·∫¶N 6: ƒê√ÅNH GI√Å HI·ªÜU SU·∫§T M√î H√åNH")
        print("="*50)
        results, best_model_name = evaluate_models(models, test_data)
        best_model = models[best_model_name]
        
        visualize_predictions(results, best_model_name)
        
        print("\n" + "="*50)
        print("PH·∫¶N 7: D·ª∞ ƒêO√ÅN TI√äU TH·ª§ NƒÇNG L∆Ø·ª¢NG NƒÇM TI·∫æP THEO")
        print("="*50)
        yearly_predictions, yearly_stats, monthly_pred_pd, next_year = predict_yearly_consumption(df_features, best_model, spark, df_clean)
        
        generate_insights(analysis_results, yearly_stats, monthly_pred_pd, next_year)
        
        save_analysis_results(analysis_results, spark)
        
        print("\n" + "="*60)
        print("üéâ HO√ÄN TH√ÄNH! Ch∆∞∆°ng tr√¨nh ƒë√£ ch·∫°y th√†nh c√¥ng!")
        print("üìä C√°c file bi·ªÉu ƒë·ªì ƒë√£ ƒë∆∞·ª£c l∆∞u:")
        print("   ‚Ä¢ energy_consumption_hourly_analysis.png")
        print("   ‚Ä¢ energy_distribution_analysis.png")
        print("   ‚Ä¢ energy_device_analysis.png")
        print("   ‚Ä¢ model_performance_comparison.png")
        print(f"   ‚Ä¢ yearly_energy_prediction_{next_year}.png")
        print("="*60)
        
    except Exception as e:
        print(f"‚ùå L·ªói: {str(e)}")
        print("üí° Ki·ªÉm tra l·∫°i:")
        print("   ‚Ä¢ ƒê∆∞·ªùng d·∫´n file d·ªØ li·ªáu")
        print("   ‚Ä¢ C·∫•u h√¨nh Hadoop/Spark")
        print("   ‚Ä¢ K·∫øt n·ªëi HDFS")
        import traceback
        traceback.print_exc()
    
    finally:
        spark.stop()
        print("üîå Spark Session ƒë√£ ƒë∆∞·ª£c ƒë√≥ng.")

if __name__ == "__main__":
    main()